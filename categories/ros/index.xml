<?xml version="1.0" encoding="utf-8" standalone="yes"?><rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>ros on technical_</title><link>https://blog.agramakov.me/categories/ros/</link><description>Recent content in ros on technical_</description><generator>Hugo</generator><language/><lastBuildDate>Wed, 31 Aug 2022 19:58:42 +0100</lastBuildDate><atom:link href="https://blog.agramakov.me/categories/ros/index.xml" rel="self" type="application/rss+xml"/><item><title>Brain Software Architecture</title><link>https://blog.agramakov.me/posts/2022/08-31-brain-software-architecture/</link><pubDate>Wed, 31 Aug 2022 19:58:42 +0100</pubDate><guid>https://blog.agramakov.me/posts/2022/08-31-brain-software-architecture/</guid><description><p>Before updating Alive OS to support<a href="https://zakhar-the-robot.github.io/doc/docs/communication-protocols/canbus/" target="_blank">qCAN (my CANbus-based protocol)</a> I have the last thing to do. To simplify my live in future I need a CAN publisher that can publish messages to many subscribers. My main subscribe of course is AliveOS but also to display information about connected devices I need a second subscriber - a service listening only qCAN Present messages.</p><p>To do it I will use a<a href="https://zeromq.org/" target="_blank">ZeroMQ protocol</a> - an extremely supported and documented for many programming languages standard. I&rsquo;m going to update my brain_service to support the protocol and it will be responsible for all interaction with Raspberry Pi.</p><p><img class="img-zoomable" src="Brain_Structure.png" alt=""/></p><p>Repositories:</p><ul><li><a href="https://github.com/Zakhar-the-Robot/brain_pycore" target="_blank">https://github.com/Zakhar-the-Robot/brain_pycore</a></li><li><a href="https://github.com/Zakhar-the-Robot/brain_service" target="_blank">https://github.com/Zakhar-the-Robot/brain_service</a></li></ul></description></item><item><title>Zakhar's Concept</title><link>https://blog.agramakov.me/posts/2019/06-01-zakhars-concept/</link><pubDate>Sat, 01 Jun 2019 00:00:00 +0000</pubDate><guid>https://blog.agramakov.me/posts/2019/06-01-zakhars-concept/</guid><description><p>It is not a secret for anybody, what we are living in the era of consumption. We produce and consume food, medical preparations and of course, the flagship of the planet&rsquo;s economics - electronics. Modern electronics are becoming more and more sophisticated, hard to understand and we have to spend time to learn it. It so, because there is a huge gap between the level of development of technics (which the main face is electronics) and user interfaces. &ldquo;User interfaces&rdquo; it is a quite new term, and researches in that fields are conducted only in the last several decades. Previously we could talk about ergonomic, but the question of how to use a technical tool was not asked hard way as now. Let&rsquo;s take a look at the most technologically advanced and widespread instrument, we have today - a smartphone. Talking about people, using it in most of the context we have to split them into &ldquo;users&rdquo; and as-called &ldquo;power users&rdquo;. The first category is the people, who are using only basic functions of the device. They can write a message, make a call, charge a device and take a photo. Commonly they are do not understand the behavior of the device, they do not know if the device could work under the water, at the cold temperatures, they are do not know how say, Android devices will cooperate with each other is touch it&rsquo;s backsides or how to transfer text from an iPhone to a MacBook. It is a really natural and normal situation, cause a man is a social creature - that is mean, the most important skills it has, how to cooperate with other people. Talking about interacting with others a middle man is a power user. That is so because of those points:</p><ol><li>To understand others is the vital skill for any highly organized animals</li><li>To understand the self is the vital skill for any form of life</li><li>Thanks the similarity of any human, the first and the second quality is connected.</li></ol><p>Because of these circumstances, we can understand each other, we can interact with each other productively, became a power user of each other. The more similarity between us and other animals, cause better cooperation. Look, how we interacting with dogs or cows, look at how we interact with jellyfish and bees. I claim, the more resembling in inner processes, especially that connected with the outer behavior tightly, the more effectiveness and simplicity we are getting during interacting. Talking about such artificial thing the technics are, we are not understanding how it works, we can not imagine how any our interact connected with the result which technics provide are - without preparations and learning of the subject. There is a lot of approaches on how to harmonize interfaces with our perception, but making systems complicated all the time requiring finding new approaches. At modern times we can talk to our smartphones, we can use unmanned transport, we are almost got robots as companions. But in many cases, without learning rules and conventions of that kind interacting of us with our technical tools is useless. I can see two main ways how to simplify interacting between users and a technics:</p><ul><li>Learn how to a technics works</li><li>Learn a technics to work like other people</li></ul><p>The first approach we are using all our modern lives, the second one became more important in the last years (Google Duplex is an ambassador of this approach). As I said we are standing on the start line of the mass robotics. But still and all the time when we are talking about it (are do that a lot!) we are considering, what the robots would be fundamentally different from life existing before. We are justifying this based on facts what electronics based on different principles than organics. And we are ready to create sophisticated robots with a straight fully logical program, which can not understand us and therefore could lead us to different problems including a total mankind extinction. We are trying to develop systems to control and to hold AI, we are afraid of the future so much what we can not see the most obvious thing. We already can control and understand each other perfectly. Evidence of this is our existing for thousands of years. I suppose, if we really want (directly or indirectly) to create a new form of life which could co-exist with us there is the one way - study yourself and make something based on that we are now is. In my robotics hobby, I’m trying to follow ideas which are at the basis of the human mind. And for it is a more interesting approach than just reproduce elements of Rumba in my robots. I was thinking a lot about how the human mind works. Fortunately almost all human culture, starting from literature ending the serials - is a clue to an understanding of this. I can tell at least 4 relatively solid and standalone parts of the human mind:</p><ol><li>Conscious - the<a href="https://cs.stanford.edu/people/eroberts/courses/soco/projects/2001-02/hci/locus.htm" target="_blank">locus of attention</a>, watcher of the current process.</li><li>Subconscious - the part of the mind where the most sophisticated thing is doing. Subconscious is learning all the time, it collects and full the input data by meaning. All the time we learning any new move in dance or yoga, subconscious being under the conscious watch trying to figure out how to connect out desire with body’s capabilities.</li><li>Unconscious - represents our reflexes and instincts. When something goes out the control, the unconscious is turning off a conscious and use subconscious with all it’s skills to follow things to a more appropriate way, say to take away a hand out a fire. It is the source of the fight-or-flight response, reaction for the pain and so on.</li><li>Autonomous systems. Not all parts of our bodies could be following by direct orders of conscience or unconscious. The heart will works until you died, the hair will grow even further and we can not change it significantly by own.</li></ol><p>At<a href="https://blog.agramakov.me/2019/05/05/zakhar-relaunch-zakha_ros/" target="_blank">my previous article</a>, I told my main robotics project - Zakhar the Robot is relaunched to get a new name,<code>Zakha_ros</code>. And following there is an idea of how it should work keeping in mind all the said previously:</p><p><img class="img-zoomable" src="za_concept.png" alt=""/></p><p>In terms of the software, Unconscious seems like the kind of actual human operating system. It could start, pause or terminate the Conscious. It is a stable core which is changing rarely and being a standalone part of our minds. Conscious - is the child process of Unconscious and the second user of the Subconscious. Talking about manned robots - it is an operator using human-computer interfaces. Talking about unmanned ones - who knows. Subconscious - is the most flexible part of the mind. This is it’s the main mass and instrument. For robots - the most logic and hardware abstraction layer concluded here. It is a rewritable program, which is updating all the time. But as a first approximation, we could consider it as a fixed one. Autonomy systems - the simplest part. It could be any device, controlled or not with other parts of a robot. But mandatory connected with the robot. Following these ideas and developing it’s the next step I’m planning to realize a moving system of<code>Zakha_ros</code>, so stay tuned!</p></description></item><item><title>Zakhar relaunch: Zakha_ros</title><link>https://blog.agramakov.me/posts/2019/05-05-zakhar-relaunch-zakha_ros/</link><pubDate>Sun, 05 May 2019 00:00:00 +0000</pubDate><guid>https://blog.agramakov.me/posts/2019/05-05-zakhar-relaunch-zakha_ros/</guid><description><p>After a lot of experiments with Raspberry, ESP32, STM32 and Arduino boards I&rsquo;ve decided what will be a spine of the<a href="https://github.com/an-dr/zakhar" target="_blank">Zakhar</a> project.<a href="https://www.ros.org/" target="_blank">ROS</a> seems the most interesting and extendible. Inside it, I could combine Python, C, C++ programs (hence, libraries ) working inside a Linux environment and communicate with any other platforms.</p><p>Say, I could build a system on a Raspberry, which will communicate with developer board like<a href="https://www.espressif.com/en/products/hardware/esp-wrover-kit/overview" target="_blank">ESP-WROVER-KIT</a> working on FreeRTOS. Even more, I could use my desktop as a part of the system for High-level computing (say, for image recognition with OpenCV).</p><p>I have bought some hardware for the new version of Zakhar, called<strong>Zakha_ros:</strong></p><h2 id="the-new-hardware">The new hardware</h2><p><strong>1. Platform.</strong> It is a simple platform which I used for my first experiments 3 years ago:</p><p><img class="img-zoomable" src="za_platform_logo.jpg" alt=""/></p><p><strong>2. Manipulator.</strong> It based on DC motor and an aluminum chassis. Nice to grab something.</p><p><img class="img-zoomable" src="za_hand_logo.jpg" alt=""/></p><p><strong>3. Camera.</strong> I&rsquo;ve bought a standard Pi camera than mounted it onto a small cardboard panel</p><p><img class="img-zoomable" src="za_camera_logo.jpg" alt=""/></p><p><strong>4. Raspberry Pi 3 B+.</strong> With a nice black case.</p><p><img class="img-zoomable" src="za_rpi_logo.jpg" alt=""/></p><p> </p><h2 id="whats-next">What&rsquo;s Next</h2><p>Next, I&rsquo;m planning to update a<a href="https://agramakov.me/wiki/doku.php?id=zakhar:main" target="_blank">Zakhar concept</a> to follow ROS capabilities and using hardware. Stay tuned!</p></description></item></channel></rss>